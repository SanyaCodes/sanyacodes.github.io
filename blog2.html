<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Blog2 — Sanya Chetwani</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body class="home-page blog-page">
  <header class="nav-wrap">
    <nav class="glass-nav container">
      <a class="logo" href="index.html">Sanya Chetwani</a>
      <ul class="nav-links">
        <li><a href="index.html">About</a></li>
        <li><a href="blog.html" aria-current="page">Blog</a></li>
        <li><a href="experience.html">Experience</a></li>
        <!-- <li><a href="contact.html">Contact</a></li> -->
      </ul>
      <button class="theme-toggle" type="button" aria-pressed="false" aria-label="Toggle theme">☾</button>
    </nav>
  </header>

  <main class="container">
    <section class="page">
      <a class="timeline-card timeline-card-link back-link" href="blog.html" aria-label="Back to blog list">
        ← Back to Blogs
      </a>
      <div class="blog-detail">
        <h1>Building a Real-Time Feature Store: Lessons from Processing 100K+ Events Daily</h1>

        <div class="role blog-body">
          <p>When we started building our ML platform at Kognitic, we had a problem that every ML team eventually faces: our models were making predictions with stale data. A clinical trial published at 9 AM wouldn't show up in our predictions until the next day's batch run. For pharma clients racing to market, that 24-hour lag was unacceptable.</p>
    
          <p>So we built a real-time feature store. Not because it was trendy, but because we needed it. Here's what actually worked, what broke spectacularly, and what I'd do differently.</p>

          <h2>The Problem: When Batch Isn't Good Enough</h2>
          
          <p>Our initial architecture was simple. Daily batch jobs would extract features from clinical trials, store them in S3, and feed them to our models. It worked fine until it didn't.</p>
          
          <p>The issue wasn't the volume - we were processing 100K+ clinical abstracts just fine. The issue was freshness. Our biomarker extraction models were analyzing yesterday's trials when clients needed insights on today's data. Feature staleness was killing our value proposition.</p>
          
          <strong>The real cost of staleness:</strong> Research shows that even one hour of feature staleness can degrade model performance significantly. For time-sensitive applications like clinical trial monitoring, fresh features aren't a luxury - they're a requirement.
          

          <h2>Architecture: Building for Freshness at Scale</h2>
          
          <h3>The Core Stack</h3>
          
          <p>We built our feature store on three pillars:</p>
          
          <ul>
              <li><strong>Apache Airflow</strong> for orchestration - coordinating the entire pipeline from ingestion to serving</li>
              <li><strong>AWS Lambda</strong> for serverless compute - processing individual events without managing servers</li>
              <li><strong>S3 + Athena</strong> for storage and querying - cheap, scalable, and familiar to our team</li>
          </ul>
          
          <p>The workflow looked like this: New clinical trial data hits S3 → S3 event triggers Lambda → Lambda invokes Airflow DAG → DAG orchestrates feature extraction → Features stored back in S3 → Athena enables real-time queries.</p>

          <h3>Why This Stack?</h3>
          
          <p>We chose serverless not because it's cool, but because it matched our workload. Clinical trial publications are bursty - hundreds might drop in the morning, then nothing for hours. Lambda's auto-scaling meant we didn't pay for idle compute. Airflow gave us the orchestration complexity we needed without the overhead of managing a scheduler.</p>
          
          <p>The key was using Airflow's <code>AwsLambdaInvokeFunctionOperator</code> to trigger Lambda functions directly from DAGs. This let us keep Airflow's dependency management while leveraging Lambda's scalability.</p>

          <h2>The Feature Freshness Problem</h2>
          
          <h3>Understanding the Lag</h3>
          
          <p>Feature freshness is the time between when raw data becomes available and when it's usable for predictions. In our case, that meant:</p>
          
          <ul>
              <li>Event detection (S3 upload) - ~5 seconds</li>
              <li>Lambda cold start - 2-3 seconds first invocation, &lt;100ms after</li>
              <li>Feature extraction (Transformer inference) - 800ms per document</li>
              <li>Storage write - 200ms</li>
              <li>Athena query availability - near-instant with proper partitioning</li>
          </ul>
          
          <p>Total latency: Under 5 seconds for most documents. Compare that to our previous 24-hour batch cycle.</p>

          <h3>The Staleness-Performance Trade-off</h3>
          
          <p>Here's what nobody tells you: real-time features are expensive. Every millisecond of freshness you gain costs compute, complexity, and money. We had to be smart about what actually needed to be real-time.</p>
          
          <p>We classified our features into three tiers:</p>
          
          <ul>
              <li><strong>Ultra-fresh</strong> (&lt;1 minute) - New trial publications, breaking news mentions</li>
              <li><strong>Near real-time</strong> (5-15 minutes) - Trial status updates, enrollment numbers</li>
              <li><strong>Batch-friendly</strong> (daily) - Historical aggregations, 30-day rolling features</li>
          </ul>
          
          <p>Only tier-1 features went through the full real-time pipeline. Everything else used scheduled batch jobs. This hybrid approach cut our compute costs by 60% while maintaining the freshness where it mattered.</p>

          <h2>Implementation Details: What Actually Worked</h2>
          
          <h3>Orchestration with Airflow + Lambda</h3>
          
          <p>Our Airflow DAGs were designed for modularity. Each DAG handled one feature type - biomarker extraction, drug-target identification, sentiment classification. Lambda functions did the heavy lifting (model inference), while Airflow managed dependencies and retries.</p>
          
          <p>The killer feature was dynamic task mapping. When 500 new trials dropped at once, Airflow would dynamically spawn 500 parallel Lambda invocations, each processing one document. No manual scaling, no queues backing up.</p>

          <h3>Handling the Transformer Model</h3>
          
          <p>Running a Transformer model in Lambda sounds crazy, but it worked with some tricks:</p>
          
          <ul>
              <li>Model quantization - Reduced our BioBERT variant from 440MB to 110MB</li>
              <li>Warm pools - Kept 10-20 Lambda instances warm during peak hours</li>
              <li>Smart batching - Grouped documents by similarity to maximize cache hits</li>
          </ul>
          
          <p>Result: 800ms average inference time, 0.87 F1 score on biomarker extraction. Good enough to beat our baselines while staying within Lambda's 15-minute timeout.</p>

          <h3>The Storage Layer</h3>
          
          <p>S3 + Athena gets a bad rap for real-time use cases, but it worked for us because:</p>
          
          <ul>
              <li>We partitioned by date and trial ID - Athena queries hit only relevant partitions</li>
              <li>Parquet format with good compression - 3x smaller than JSON, faster to scan</li>
              <li>Proper schema design - Denormalized where it made sense, avoiding expensive joins</li>
          </ul>
          
          <p>Athena query latency averaged 2-3 seconds for feature retrieval. Not sub-second, but fast enough for our use case and way cheaper than maintaining a dedicated online store.</p>

          <h2>What Broke (And How We Fixed It)</h2>
          
          <h3>Lambda Cold Starts</h3>
          
          <p>First week in production: cold starts were killing us. 2-3 second delays for the first invocation of each Lambda instance meant features could take 10+ seconds to compute.</p>
          
          <p>Fix: Provisioned concurrency for core functions during business hours (9 AM - 6 PM EST). Cost went up 15%, latency went down 70%. Worth it.</p>

          <h3>Airflow Task Queueing</h3>
          
          <p>When trial publications spiked, Airflow's task queue would back up. We were hitting the scheduler's limits.</p>
          
          <p>Fix: Increased scheduler resources and implemented task priority. Critical features (new trial publications) got priority queue access. Batch aggregations could wait.</p>

          <h3>Feature Drift Between Training and Serving</h3>
          
          <p>This one was subtle. Our training pipeline used batch features from S3. Our serving pipeline used real-time features from the feature store. Slight differences in preprocessing logic caused a train-serve skew that dropped our F1 score by 0.05.</p>
          
          <p>Fix: Shared feature transformation code. We extracted all preprocessing into reusable Lambda layers that both training and serving pipelines imported. Version-controlled, tested, and identical across environments.</p>

          <h2>The Numbers: Impact and Cost</h2>
          
          <p>After six months in production, here's what we achieved:</p>
          
          <ul>
              <li>Reduced manual update time by 90% - from daily manual reviews to automated hourly updates</li>
              <li>Cut operational latency by 75% - from 24-hour batch cycles to 5-minute freshness</li>
              <li>Processing 5K+ new trials per month - fully automated with no human intervention</li>
              <li>Monthly AWS costs: ~$2,400 (Lambda: $800, S3: $400, Athena: $600, Airflow on EC2: $600)</li>
          </ul>
          
          <p>For context, our previous batch system cost ~$1,800/month but delivered day-old features. The extra $600/month bought us real-time insights that directly translated to faster client decisions.</p>

          <h2>Lessons Learned</h2>
          
          <h3>Real-Time Isn't All-or-Nothing</h3>
          
          <p>The biggest lesson: you don't need to make everything real-time. Identify the 20% of features that drive 80% of your freshness requirements. Make those real-time. Keep the rest on batch schedules.</p>
          
          <p>We wasted two weeks trying to make historical aggregations real-time before realizing nobody cared if "30-day trial count" was computed yesterday or five minutes ago.</p>

          <h3>Observability Is Everything</h3>
          
          <p>You can't optimize what you can't measure. We instrumented everything - feature computation time, Lambda cold start frequency, Athena query latency, feature staleness per type. CloudWatch dashboards became our single source of truth.</p>
          
          <p>When something broke at 3 AM (and it did), we could pinpoint the issue in minutes instead of hours.</p>

          <h3>Start Simple, Scale Complexity</h3>
          
          <p>Our first version was embarrassingly simple. S3 → Lambda → S3. No Airflow, no fancy orchestration. It handled 1K documents/day just fine. We added Airflow only when coordination complexity became painful. We added provisioned concurrency only when cold starts became a bottleneck.</p>
          
          <p>Don't over-engineer upfront. Build the minimum viable feature store, then add complexity only when you feel the pain.</p>

          <h2>The 2024 Feature Store Landscape</h2>
          
          <p>Since we built our system, the feature store ecosystem has evolved rapidly. Companies like Etsy, Stripe, and Uber have shared their approaches. A few patterns have emerged:</p>
          
          <ul>
              <li><strong>Streaming-first architecture</strong> - Flink and Kafka for sub-second freshness</li>
              <li><strong>Vector embeddings</strong> - Feature stores now integrate with vector databases for LLM applications</li>
              <li><strong>Lakehouse integration</strong> - Delta, Iceberg, and Hudi for unified batch and streaming</li>
              <li><strong>Managed services</strong> - Platforms like Tecton, Hopsworks, and AWS SageMaker Feature Store</li>
          </ul>
          
          <p>If I were building this today, I'd seriously consider a managed solution. The operational overhead of maintaining a feature store is real. But for teams with specific requirements or tight budgets, rolling your own with Airflow + Lambda is still viable.</p>

          <h2>What's Next</h2>
          
          <p>We're now working on near real-time embedding generation. Our Transformer models produce embeddings that downstream models consume, but these embeddings are currently regenerated daily. Moving to streaming updates would unlock more adaptive recommendations.</p>
          
          <p>We're also exploring Apache Flink for true streaming aggregations. Lambda works great for document-level features, but time-window aggregations (e.g., "trials published in the last hour") are clunky with our current setup.</p>

          <h2>Final Thoughts</h2>
          
          <p>Building a real-time feature store taught me that "real-time" is a spectrum, not a binary. Every millisecond of freshness has a cost - in complexity, compute, and engineering time. The art is finding the right trade-off for your use case.</p>
          
          <p>For us, going from 24-hour to 5-minute freshness was transformative. Going from 5 minutes to 5 seconds? Probably not worth it. Know what matters for your application.</p>
          
          <p>If you're building ML systems at scale, you'll eventually need a feature store. Start simple, measure everything, and scale complexity only when necessary. Your future self will thank you.</p>
    
        </div>
      </div>

    </section>
  </main>
  <button class="back-to-top" aria-label="Scroll back to top">↑</button>

  <footer class="container footer">
    <p>© Sanya Chetwani</p>
  </footer>
  <script>
    (function() {
      const backToTopBtn = document.querySelector('.back-to-top');
      const toggleBackToTop = () => {
        if (!backToTopBtn) return;
        backToTopBtn.classList.toggle('show', window.scrollY > 200);
      };
      window.addEventListener('scroll', toggleBackToTop);
      backToTopBtn?.addEventListener('click', () => window.scrollTo({ top: 0, behavior: 'smooth' }));
      toggleBackToTop();

      const storageKey = 'theme-preference';
      const toggleBtn = document.querySelector('.theme-toggle');
      const applyTheme = (theme) => {
        const isDark = theme === 'dark';
        document.body.classList.toggle('theme-dark', isDark);
        if (toggleBtn) {
          toggleBtn.setAttribute('aria-pressed', String(isDark));
          toggleBtn.textContent = isDark ? '☀' : '☾';
        }
      };
      const storedTheme = localStorage.getItem(storageKey);
      const prefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
      applyTheme(storedTheme || 'light');
      toggleBtn?.addEventListener('click', () => {
        const newTheme = document.body.classList.contains('theme-dark') ? 'light' : 'dark';
        applyTheme(newTheme);
        localStorage.setItem(storageKey, newTheme);
      });
    })();
  </script>
</body>
</html>
